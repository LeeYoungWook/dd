{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPcomparison.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeYoungWook/dd/blob/master/MLPcomparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGgsUbEKh9h6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "attD6ljTYRim",
        "colab_type": "code",
        "outputId": "fed424c8-3532-42f9-ef86-d6bbbf4ee742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "img = utils.make_grid(images, padding=0)\n",
        "npimg = img.numpy() # img를 넘파이 행렬로 변환\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(np.transpose(npimg, (1,2,0))) # 첫번째, 두번째 차원을 읽어 이미지로 나타냄\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1fef02bcb629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnpimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# img를 넘파이 행렬로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 첫번째, 두번째 차원을 읽어 이미지로 나타냄\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOsQHsIvYUhA",
        "colab_type": "code",
        "outputId": "c247c014-f512-436f-a9d2-4b27755c34c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "# 토치비전과 파이토치 패키지 불러오기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.utils import data\n",
        "\n",
        "# CUDA(pytorch에서 GPU를 사용하게 해주는 도구)설치 여부를 기준으로 GPU / CPU 사용 결정\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "# DEVICE 변수를 통해 나중에 텐서 및 가중치 연산에서 GPU / CPU 사용결정\n",
        "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
        "\n",
        "# 이폭은 학습 데이터 전체를 총 몇 번이나 볼 것인가에 대한 설정\n",
        "EPOCHS=20\n",
        "BATCH_SIZE=128\n",
        "\n",
        "# 데이터 전처리 과정을 적용(이미지 텐서변환, 랜덤으로 뒤집기, 정규화)하여 Fashion MNIST 데이터셋 가져오기 / * 정규화 방식 차이 설명(0~255와 0~1의 차이)\n",
        "# 학습용 트레닝 셋(Train=True)\n",
        "train_loader=torch.utils.data.DataLoader(datasets.FashionMNIST('./.data', train=True, download=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])), batch_size=BATCH_SIZE, shuffle=True)\n",
        "# 성능 평가용 데이터셋(Train=False)\n",
        "test_loader=torch.utils.data.DataLoader(datasets.FashionMNIST('./.data', train=False, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])), batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# * 파이토치는 항상 모델 구현 시에 nn.Module을 상속하는 클래스를 생성함 nn 속의 함수들을 이용하기 위함.\n",
        "class Net(nn.Module):\n",
        "    # 드롭아웃 확률 = 0.45로 설정, 즉 학습 시 45% 뉴런을 사용하지 않음\n",
        "    def __init__(self, dropout_p=0.45):\n",
        "        super(Net, self).__init__()\n",
        "        # 함수 fc1()은 픽셀값 784개를 입력받아 가중치를 행렬곱하고 편향을 더해 값 256개를 출력\n",
        "        self.fc1 = nn.Linear(784,256)\n",
        "        # fc2()와 fc3() 함수를 거쳐 마지막에 값 10개를 출력\n",
        "        self.fc2 = nn.Linear(256,128)\n",
        "        # 출력값 10개는 각각의 클래스를 나타내며 가장 큰 값이 이 모델의 예측값\n",
        "        self.fc3 = nn.Linear(128,10)\n",
        "        self.dropout_p = dropout_p # 드롭아웃 확률\n",
        "    \n",
        "    # 순전파\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,784)\n",
        "        x = F.relu(self.fc1(x))\n",
        "    # 학습모델에서만 드롭아웃을 적용하기 위한 self.training 입력\n",
        "        x = F.dropout(x, training=self.training, p=self.dropout_p)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, training=self.training, p=self.dropout_p)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델 선언\n",
        "# CUDA를 사용할 경우 GPU를 아닐 경우 CPU로 보내도록 설정\n",
        "model=Net(dropout_p=0.45).to(DEVICE)\n",
        "# 최적화 알고리즘으로 파이토치 내장 모듈인 optim.SGD(확률적 경사하강법) 사용\n",
        "# model.parameters()는 모델 내부의 정보를 넘겨줌, lr=학습률\n",
        "optimizer=optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "def train(model, train_loader, optimizer): # 각 인자는 모델, 데이터 공급, 최적화 역할\n",
        "    model.train() # 모델을 학습 모드로 설정\n",
        "    # 배치마다의 data, target에 대한 정보를 DEVICE로 보냄\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target=data.to(DEVICE), target.to(DEVICE)\n",
        "    # 반복 때마다 기울기를 새로 계산(누적하지 않음)하므로 zero_grad() 설정 / * 파이토치에는 기울기 누적을 실행하지 않는 zero_grad 설정\n",
        "        optimizer.zero_grad()\n",
        "        output=model(data)\n",
        "    # 교차 엔트로피 사용하여 오차 구함\n",
        "    # loss는 미니배치 128개의 오차들의 평균인 하나의 숫자\n",
        "        loss=F.cross_entropy(output, target)\n",
        "    # backward 함수를 실행하면 자동으로 기울기가 계산\n",
        "        loss.backward()\n",
        "    # 계산한 기울기를 앞서 정의한 알고리즘(SGD)에 맞추어 가중치 수정(매개변수 갱신)\n",
        "        optimizer.step()\n",
        "\n",
        "# 이폭이 끝날 때마다 테스트셋으로 모델의 성능 측정하는 evaluate 함수 생성\n",
        "def evaluate(model, test_loader): # 평가가 목적이므로 최적화는 필요 없음\n",
        "    model.eval() # 모델을 평가 모드로 변경\n",
        "    test_loss=0\n",
        "    correct=0\n",
        "    # 평가 과정에서는 기울기를 계산하지 않아도 됨\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader :\n",
        "            data, target=data.to(DEVICE), target.to(DEVICE)\n",
        "            output=model(data)\n",
        "    # 평가를 위해 미니배치들의 평균 대신 합을 받아오도록 reduction='sum' 설정, 즉 모든 오차의 합 출력\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "    # 예측값. output.max()는 가장 큰 값과 그 인덱스를 출력. 그 중 인덱스 이용\n",
        "            pred=output.max(1,keepdim=True)[1]\n",
        "    # eq함수는 일치하면 1, 아니면 0 출력. sum함수로 배열 내 값 모두 더하여 배치에서 모델이 정답을 맞힌 개수 구함\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    # 총 정답 평균을 구하여 정확도를 구함\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy=100.*correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train(model, train_loader, optimizer) # 훈련 후 평가\n",
        "    test_loss, test_accuracy=evaluate(model, test_loader)\n",
        "    # 오차는 소숫점 4자리까지, 정확도는 소숫점 2자리까지\n",
        "    print('[{}] Test Loss : {:.4f}, Accuracy : {:.2f}%'.format(epoch, test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] Test Loss : 0.8630, Accuracy : 69.13%\n",
            "[2] Test Loss : 0.6848, Accuracy : 75.05%\n",
            "[3] Test Loss : 0.6026, Accuracy : 78.19%\n",
            "[4] Test Loss : 0.5565, Accuracy : 79.73%\n",
            "[5] Test Loss : 0.5293, Accuracy : 80.33%\n",
            "[6] Test Loss : 0.5093, Accuracy : 81.20%\n",
            "[7] Test Loss : 0.4934, Accuracy : 81.75%\n",
            "[8] Test Loss : 0.4793, Accuracy : 82.37%\n",
            "[9] Test Loss : 0.4700, Accuracy : 82.78%\n",
            "[10] Test Loss : 0.4577, Accuracy : 83.07%\n",
            "[11] Test Loss : 0.4508, Accuracy : 83.67%\n",
            "[12] Test Loss : 0.4468, Accuracy : 83.80%\n",
            "[13] Test Loss : 0.4393, Accuracy : 84.16%\n",
            "[14] Test Loss : 0.4320, Accuracy : 84.30%\n",
            "[15] Test Loss : 0.4282, Accuracy : 84.59%\n",
            "[16] Test Loss : 0.4223, Accuracy : 84.76%\n",
            "[17] Test Loss : 0.4170, Accuracy : 85.16%\n",
            "[18] Test Loss : 0.4128, Accuracy : 85.19%\n",
            "[19] Test Loss : 0.4168, Accuracy : 84.93%\n",
            "[20] Test Loss : 0.4063, Accuracy : 85.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqsCtyoLvxha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKMB19lIX73k",
        "colab_type": "code",
        "outputId": "23209a3e-19b5-487d-da9e-19344576af7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "summary(model, (1, 784))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 256]         200,960\n",
            "            Linear-2                  [-1, 128]          32,896\n",
            "            Linear-3                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.90\n",
            "Estimated Total Size (MB): 0.90\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}