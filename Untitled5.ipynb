{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOADYkaQzVrY6auKLwiUsMt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeYoungWook/dd/blob/master/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w88zu3E6FJ7e",
        "colab_type": "text"
      },
      "source": [
        "# **## 7.2.1 자연어 전처리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgQvvbkYCz8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#영화 리뷰 분석\n",
        "\n",
        "#토치비전이 아닌 토치테스트로 모델 구현과 학습에 필요한 라이브러리를 임포트함\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data, datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbt4guTsDQ3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#모델 구현과 학습에 필요한 하이퍼파라미터들을 정의함\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "lr = 0.001\n",
        "EPOCHS = 10\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWSAqweKDamv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#신경망 학습에 쓰일 IMDB데이터셋을 로딩하고 텐서로 변환한다. \n",
        "#텍스트 형태의 영화 리뷰들을 텐서로 바꿔줄때 필요한 설정을 한다.\n",
        "\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.Field(sequential=False, batch_first=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByO4sp_lDbuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splits()함수를 이용해 모델에 입력되는 데이터셋을 만들어준다.\n",
        "\n",
        "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrSJNK2IDe8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 만들어진 데이터셋을 이용해 워드 임베딩에 필요한 단어 사전을 만든다.\n",
        "# min_freq5 는 최소 5번 이상 등장한 단어만 사전에 담겠다.\n",
        "\n",
        "TEXT.build_vocab(trainset, min_freq=5)\n",
        "LABEL.build_vocab(trainset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usRZXtQoEjqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#학습용 데이터셋을 학습셋 80%, 검증셋20%으로 나눈다.\n",
        "\n",
        "trainset, valset = trainset.split(split_ratio=0.8)\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "        (trainset, valset, testset), batch_size=BATCH_SIZE,\n",
        "        shuffle=True, repeat=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxHBi-HTEY5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 사전 속 단어들의 개수와 레이블의 수를 정해주는 변수를 만든다.\n",
        "\n",
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPz9POzNFBjo",
        "colab_type": "code",
        "outputId": "9eb5e012-7599-469f-c52c-7ad981d4655a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#학습셋, 검증셋, 그리고 테스트셋의 예제 개수를 각각 출력해 확인한다.\n",
        "\n",
        "\n",
        "print(\"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d\"\n",
        "      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어수]: 46159 [클래스] 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT7knCyyR4JG",
        "colab_type": "text"
      },
      "source": [
        "# **7.2.2 RNN 모델 구현**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_JdTc-sR0qP",
        "colab_type": "code",
        "outputId": "4f859c04-c1ef-492b-9d31-ff927507d723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "class BasicGRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(BasicGRU, self).__init__()\n",
        "        print(\"Building Basic GRU model...\")\n",
        "        self.n_layers = n_layers\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        h_0 = self._init_state(batch_size=x.size(0))\n",
        "        x, _ = self.gru(x, h_0)  # [i, b, h]\n",
        "        h_t = x[:,-1,:]\n",
        "        self.dropout(h_t)\n",
        "        logit = self.out(h_t)  # [b, h] -> [b, o]\n",
        "        return logit\n",
        "    \n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n",
        "\n",
        "\n",
        "def train(model, optimizer, train_iter):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1)  # 레이블 값을 0과 1로 변환\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def evaluate(model, val_iter):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    corrects, total_loss = 0, 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "    size = len(val_iter.dataset)\n",
        "    avg_loss = total_loss / size\n",
        "    avg_accuracy = 100.0 * corrects / size\n",
        "    return avg_loss, avg_accuracy\n",
        "\n",
        "\n",
        "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "best_val_loss = None\n",
        "for e in range(1, EPOCHS+1):\n",
        "    train(model, optimizer, train_iter)\n",
        "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
        "\n",
        "    print(\"[이폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n",
        "    \n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        if not os.path.isdir(\"snapshot\"):\n",
        "            os.makedirs(\"snapshot\")\n",
        "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
        "        best_val_loss = val_loss\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iter)\n",
        "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Basic GRU model...\n",
            "[이폭: 1] 검증 오차: 0.71 | 검증 정확도:50.86\n",
            "[이폭: 2] 검증 오차: 0.70 | 검증 정확도:50.10\n",
            "[이폭: 3] 검증 오차: 0.67 | 검증 정확도:59.70\n",
            "[이폭: 4] 검증 오차: 0.50 | 검증 정확도:76.46\n",
            "[이폭: 5] 검증 오차: 0.33 | 검증 정확도:86.00\n",
            "[이폭: 6] 검증 오차: 0.31 | 검증 정확도:87.28\n",
            "[이폭: 7] 검증 오차: 0.33 | 검증 정확도:86.94\n",
            "[이폭: 8] 검증 오차: 0.36 | 검증 정확도:87.44\n",
            "[이폭: 9] 검증 오차: 0.40 | 검증 정확도:86.68\n",
            "[이폭: 10] 검증 오차: 0.42 | 검증 정확도:87.50\n",
            "테스트 오차:  0.34 | 테스트 정확도: 86.43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_05Bw0_LRAO",
        "colab_type": "text"
      },
      "source": [
        "# **7.3 SEQ2SEQ 기계번역**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY8pGipYLXmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk6uF3KfLk0l",
        "colab_type": "code",
        "outputId": "fa736d00-defd-40d1-a400-974f22d2db7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "vocab_size = 256  # 총 아스키 코드 개수\n",
        "x_ = list(map(ord, \"hello\"))  # 아스키 코드 리스트로 변환\n",
        "y_ = list(map(ord, \"hola\"))   # 아스키 코드 리스트로 변환\n",
        "print(\"hello -> \", x_)\n",
        "print(\"hola  -> \", y_)\n",
        "\n",
        "\n",
        "x = torch.LongTensor(x_)\n",
        "y = torch.LongTensor(y_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello ->  [104, 101, 108, 108, 111]\n",
            "hola  ->  [104, 111, 108, 97]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_1EV521PXFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.n_layers = 1\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.encoder = nn.GRU(hidden_size, hidden_size)\n",
        "        self.decoder = nn.GRU(hidden_size, hidden_size)\n",
        "        self.project = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # 인코더에 들어갈 입력\n",
        "        initial_state = self._init_state()\n",
        "        embedding = self.embedding(inputs).unsqueeze(1)\n",
        "        # embedding = [seq_len, batch_size, embedding_size]\n",
        "        \n",
        "        # 인코더 (Encoder)\n",
        "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
        "        # encoder_output = [seq_len, batch_size, hidden_size]\n",
        "        # encoder_state  = [n_layers, seq_len, hidden_size]\n",
        "\n",
        "        # 디코더에 들어갈 입력\n",
        "        decoder_state = encoder_state\n",
        "        decoder_input = torch.LongTensor([0])\n",
        "        \n",
        "        # 디코더 (Decoder)\n",
        "        outputs = []\n",
        "        \n",
        "        for i in range(targets.size()[0]):\n",
        "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
        "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
        "            projection = self.project(decoder_output)\n",
        "            outputs.append(projection)\n",
        "            \n",
        "            #티처 포싱(Teacher Forcing) 사용\n",
        "            decoder_input = torch.LongTensor([targets[i]])\n",
        "\n",
        "        outputs = torch.stack(outputs).squeeze()\n",
        "        return outputs\n",
        "    \n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhaLVbRGPaHH",
        "colab_type": "code",
        "outputId": "9f6772d9-508e-4ecf-a47c-a3d434d04754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "seq2seq = Seq2Seq(vocab_size, 16)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-3)\n",
        "\n",
        "log = []\n",
        "for i in range(1000):\n",
        "    prediction = seq2seq(x, y)\n",
        "    loss = criterion(prediction, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_val = loss.data\n",
        "    log.append(loss_val)\n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
        "        _, top1 = prediction.data.topk(1, 1)\n",
        "        print([chr(c) for c in top1.squeeze().numpy().tolist()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 반복:0 오차: 5.4723005294799805\n",
            "['\\x88', 'þ', 'y', '7']\n",
            "\n",
            " 반복:100 오차: 1.8788716793060303\n",
            "['h', 'h', 'a', 'a']\n",
            "\n",
            " 반복:200 오차: 0.7044644951820374\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:300 오차: 0.3847758173942566\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:400 오차: 0.23120951652526855\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:500 오차: 0.14231133460998535\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:600 오차: 0.09366710484027863\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:700 오차: 0.06736928224563599\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:800 오차: 0.05155593156814575\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:900 오차: 0.041131630539894104\n",
            "['h', 'o', 'l', 'a']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQzYRK--PeoG",
        "colab_type": "code",
        "outputId": "c829b3fe-7f70-4bee-8b99-8e3e375c6041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(log)\n",
        "plt.ylabel('cross entropy loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD4CAYAAADmWv3KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLyISU/8fxHQPElu0Wu8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}